# 烹饪视频菜谱提取完整流程说明

## 📋 流程概览

这是一个三阶段的自动化流程，用于从烹饪视频/图片中提取完整、精确的菜谱：

```
原始文件（视频/图片/文本）
    ↓
【阶段一】初步提取
    ↓
初步菜谱 (_recipe [✓].md)
    ↓
【阶段二】精细化分析
    ↓
缺漏分析 + 截图时间表 (_refined.md)
    ↓
【阶段三】视觉补充
    ↓
完整菜谱 + 视频片段
```

---

## 🚀 阶段一：初步提取

**目标**：从原始文件生成初步的菜谱内容

### 处理逻辑

#### 1️⃣ 视频文件（.mp4, .avi 等）
```
视频文件
  ↓
【检查字幕】是否存在 .srt 文件？
  ├─ 否 → 调用 FunASR 进行语音识别 → 生成 .srt
  └─ 是 → 跳过 ASR
  ↓
【提取菜谱】从字幕文本提取菜谱内容（调用 Ollama/DeepSeek）
  ↓
生成：{视频名}_recipe [✓].md
```

**涉及模块**：
- `fur.py` - FunASR 语音识别
- `file_processor.py` - 文件处理器

#### 2️⃣ 图片文件（.jpg, .png 等）
```
图片文件
  ↓
【视觉识别】调用 Qwen-VL 识别菜谱内容
  ↓
生成：{图片名}_recipe [✓].md
```

#### 3️⃣ Markdown 文件（.md）
```
Markdown 文件
  ↓
【格式优化】调用 LLM 优化为标准菜谱格式
  ↓
生成：{原文件名} [✓].md
```

### 输出结果
- ✅ 标记的 Markdown 文件（包含初步菜谱）
- 视频的 SRT 字幕文件

---

## 🔍 阶段二：精细化分析

**目标**：评估菜谱完整性，识别缺漏细节，生成视频截图时间表

### 处理逻辑

```
{视频名}_recipe [✓].md (菜谱)
    +
{视频名}.srt (字幕)
    ↓
【对比分析】
  1. 评估字幕完整性（0-10 分）
  2. 识别缺漏的关键烹饪细节
  3. 推测需要截图的时间点
    ↓
【生成时间表】FRAME_EXTRACTION_TABLE
  - 时间戳（HH:MM:SS）
  - 截图用途
  - 缺漏细节
  - 优先级
    ↓
生成：{视频名}_recipe [✓]_refined.md
```

**涉及模块**：
- `fine_grained_processor.py`

### 输出结果示例

```markdown
## 完整性评分
COMPLETENESS_SCORE: 6
COMPLETENESS_REASON: 字幕描述了大致步骤，但缺乏视觉细节

## 缺漏内容分析

### 缺漏细节清单
MISSING_DETAILS:
- 细节1：蛋液的稠度和气泡状态
- 细节2：锅内油温的判断标准
- 细节3：翻面时饼的颜色和形态

## 视频截图时间表
FRAME_EXTRACTION_TABLE:

| 序号 | 时间戳 | 截图用途 | 缺漏细节 | 优先级 |
|-----|-------|---------|--------|--------|
| 1 | 00:02:15 | 蛋液搅拌状态 | 确认蛋液的流动性和气泡密度 | HIGH |
| 2 | 00:03:42 | 下锅时的油温 | 观察油面波纹判断温度 | HIGH |
| 3 | 00:05:20 | 翻面时机 | 饼底部颜色和边缘状态 | MEDIUM |

TABLE_END
```

---

## 🎬 阶段三：视觉补充与剪辑

**目标**：根据时间表提取视频关键帧，用视觉模型补充细节，生成完整菜谱

### 处理逻辑

```
{视频名}_recipe [✓]_refined.md (时间表)
    +
{视频名}.mp4 (原视频)
    ↓
【遍历时间表】对每个时间戳：
  1. 确定片段范围（时间戳 ± context_window）
  2. 从片段中提取多帧截图（自适应帧数）
    ↓
【视觉问答】
  - 传入多帧截图给 Qwen-VL
  - 提问缺漏细节
  - 获取详细回答和关键时间段
    ↓
【生成剪辑】
  - 根据回答的时间段剪辑视频片段
  - 应用 margin 扩展上下文
    ↓
【汇总输出】
  - 完整的问答文档
  - 所有视频片段
    ↓
生成目录结构：
{视频名}/
  ├── clips/
  │   ├── clip_01.mp4
  │   ├── clip_02.mp4
  │   └── ...
  ├── frames/
  │   ├── task_01/
  │   │   ├── frame_00.png
  │   │   └── ...
  │   └── ...
  └── {视频名}_enriched_with_timestamps.md
```

**涉及模块**：
- `frame_clip_pipeline_v2.py`

### 输出结果示例

```markdown
# 视觉问答与时间戳标注

## 问题 1 - HIGH
**缺漏细节**: 蛋液的稠度和气泡状态
**截图用途**: 蛋液搅拌状态

### 模型回答
根据截图分析，蛋液在充分搅拌后呈现以下特征：
- 流动性良好，用筷子挑起时呈丝状流下
- 表面有细密均匀的气泡层
- 颜色均匀，无明显蛋清和蛋黄分离
- 关键时间段：00:15 - 00:45（相对片段起点）

**建议时间段**: 00:02:30 - 00:03:00 (相对原视频)
**剪辑文件**: [clip_01.mp4](clips/clip_01.mp4)

---
```

---

## 🎯 使用方法

### 方式一：运行完整流程（推荐）

```python
# 编辑 main_pipeline.py 中的配置
folder_path = r"C:\Users\magic\Desktop\烹饪"

# 运行
python main_pipeline.py
```

### 方式二：单独运行某个阶段

```python
from main_pipeline import CookingRecipePipeline

pipeline = CookingRecipePipeline(folder_path=r"C:\Users\magic\Desktop\烹饪")

# 只运行阶段一
pipeline.stage_1_initial_extraction()

# 只运行阶段二
pipeline.stage_2_fine_grained_analysis()

# 只运行阶段三
pipeline.stage_3_visual_enhancement()

# 运行阶段二和三（跳过阶段一）
pipeline.run_full_pipeline(skip_stages=[1])
```

### 方式三：使用原始脚本（分步执行）

```bash
# 阶段一
python file_processor.py

# 阶段二
python fine_grained_processor.py

# 阶段三
python frame_clip_pipeline_v2.py
```

---

## ⚙️ 配置说明

### config.json 配置文件

```json
{
  "api_provider": "deepseek",  // 或 "ollama"
  
  "ollama": {
    "base_url": "http://localhost:11434",
    "model": "qwen3-vl:32b"
  },
  
  "deepseek": {
    "base_url": "https://api.deepseek.com/v1",
    "api_key": "sk-your-api-key",
    "model": "deepseek-reasoner"
  },
  
  "prompts": {
    "image_recognition": "...",
    "markdown_optimize": "...",
    "subtitle_recipe_extraction": "..."
  },
  
  "fine_grained_processor": {
    "prompt_template": "..."
  }
}
```

### frame_clip_pipeline_v2.py 参数调整

在文件顶部修改常量：

```python
DEFAULT_CONTEXT_WINDOW = 5      # 截取时间戳前后各5秒
DEFAULT_MIN_FRAMES = 5          # 每段最少帧数
DEFAULT_MAX_FRAMES = 20         # 每段最多帧数
DEFAULT_SECONDS_PER_FRAME = 1.5 # 抽帧间隔
DEFAULT_CLIP_MARGIN = 2.0       # 剪辑扩展秒数
DEFAULT_IMAGE_MAX_SIDE = 1280   # 图像最长边
DEFAULT_IMAGE_QUALITY = 90      # JPEG 质量
```

---

## 📦 依赖安装

```bash
# 基础依赖
pip install requests pillow

# 视频处理
pip install moviepy

# 语音识别（阶段一）
pip install funasr modelscope

# 命令行工具
# 需要安装 ffmpeg（用于音频提取和视频剪辑）
```

---

## 🎓 典型使用场景

### 场景 1：处理新下载的烹饪视频
```python
# 放入文件夹后直接运行完整流程
python main_pipeline.py

# 输出：
# 1. {视频名}.srt - 字幕
# 2. {视频名}_recipe [✓].md - 初步菜谱
# 3. {视频名}_recipe [✓]_refined.md - 缺漏分析
# 4. {视频名}/ - 完整菜谱 + 视频片段
```

### 场景 2：已有字幕的视频
```python
# 跳过 ASR，直接从阶段一开始
# file_processor.py 会自动检测 .srt 文件并跳过 ASR
python main_pipeline.py
```

### 场景 3：只做精细化分析（已有初步菜谱）
```python
pipeline = CookingRecipePipeline(folder_path)
pipeline.run_full_pipeline(skip_stages=[1])  # 跳过阶段一
```

### 场景 4：批量处理图片菜谱
```python
# 将所有菜谱图片放入文件夹
# 只运行阶段一即可
pipeline = CookingRecipePipeline(folder_path)
pipeline.stage_1_initial_extraction()
```

---

## 🔧 常见问题

### Q1: 如何切换 Ollama 和 DeepSeek？
编辑 `config.json`，修改 `"api_provider"` 字段。

### Q2: 如何调整视频截图数量？
修改 `frame_clip_pipeline_v2.py` 中的 `DEFAULT_MIN_FRAMES` 和 `DEFAULT_MAX_FRAMES`。

### Q3: 如何处理子文件夹？
在 `main_pipeline.py` 中设置 `recursive=True`（默认启用）。

### Q4: 如何避免重复处理？
流程会自动检测已有的标记文件（`[✓]`），跳过已处理的内容。

### Q5: 推理模型（deepseek-reasoner）的优势？
- 更深入的分析能力
- 更准确的缺漏识别
- 会显示推理过程

---

## 📝 文件命名规则

```
原始文件：
  云南的早餐多着呢~米浆粑粑看招！.mp4

阶段一输出：
  云南的早餐多着呢~米浆粑粑看招！.srt
  云南的早餐多着呢~米浆粑粑看招！_recipe [✓].md

阶段二输出：
  云南的早餐多着呢~米浆粑粑看招！_recipe [✓]_refined.md

阶段三输出：
  云南的早餐多着呢~米浆粑粑看招！/
    ├── clips/
    ├── frames/
    └── 云南的早餐多着呢~米浆粑粑看招！_enriched_with_timestamps.md
```

---

## ✅ 总结

这个完整流程将原始的烹饪视频/图片转化为：
1. ✅ 结构化的菜谱文档
2. ✅ 精确的时间戳标注
3. ✅ 关键画面的视频片段
4. ✅ 视觉细节的补充说明

非常适合用于：
- 📚 烹饪教学资料整理
- 🎥 视频内容结构化
- 📖 菜谱知识库构建
- 🔍 烹饪细节研究
